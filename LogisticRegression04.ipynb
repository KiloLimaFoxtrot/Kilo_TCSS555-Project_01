{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LogisticRegression.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9oOtPVfD6VW","executionInfo":{"status":"ok","timestamp":1607914034281,"user_tz":480,"elapsed":2734,"user":{"displayName":"Kilo Foxtrot","photoUrl":"","userId":"09050612561505422159"}},"outputId":"af8e80b3-47ff-4214-f129-4b0f884cc7ca"},"source":["import pandas as pd\r\n","import numpy as np\r\n","import time\r\n","import io\r\n","import requests\r\n","from numpy import array\r\n","from numpy import argmax\r\n","from sklearn.preprocessing import LabelEncoder\r\n","from sklearn.preprocessing import OneHotEncoder\r\n","from nltk.tokenize import word_tokenize\r\n","from nltk import pos_tag\r\n","from nltk.corpus import stopwords\r\n","from nltk.stem import WordNetLemmatizer\r\n","from sklearn.preprocessing import LabelEncoder\r\n","from collections import defaultdict\r\n","from nltk.corpus import wordnet as wn\r\n","from sklearn.feature_extraction.text import TfidfVectorizer\r\n","from sklearn.model_selection import GridSearchCV\r\n","from sklearn import model_selection, svm\r\n","from sklearn.metrics import accuracy_score\r\n","from sklearn.model_selection import StratifiedShuffleSplit\r\n","from sklearn.metrics import classification_report\r\n","from sklearn.linear_model import LogisticRegression\r\n","from sklearn.model_selection import cross_val_score\r\n","\r\n","#Get Processed Data\r\n","url=\"https://raw.githubusercontent.com/mgcresswell/TCSS555-Project/main/deceptive-opinion_processed.csv\"\r\n","s=requests.get(url).content\r\n","Corpus = pd.read_csv(io.StringIO(s.decode('utf-8')))\r\n","\r\n","y = Corpus['deceptive']\r\n","X = Corpus.drop(['id','deceptive'], axis=1)\r\n","\r\n","label_encoder = LabelEncoder()\r\n","y = label_encoder.fit_transform(y)\r\n","hotelEncoded = label_encoder.fit_transform(X['hotel'])\r\n","polarityEncoded = label_encoder.fit_transform(X['polarity'])\r\n","sourceEncoded = label_encoder.fit_transform(X['source'])\r\n","\r\n","onehot_encoder = OneHotEncoder(sparse=False)\r\n","hotelEncoded = hotelEncoded.reshape(len(hotelEncoded), 1)\r\n","X['hotel'] = onehot_encoder.fit_transform(hotelEncoded)\r\n","polarityEncoded = polarityEncoded.reshape(len(polarityEncoded), 1)\r\n","X['polarity'] = onehot_encoder.fit_transform(polarityEncoded)\r\n","sourceEncoded = sourceEncoded.reshape(len(sourceEncoded), 1)\r\n","X['source'] = onehot_encoder.fit_transform(sourceEncoded)\r\n","\r\n","Tfidf_vect = TfidfVectorizer(max_features=3500)\r\n","Tfidf_vect.fit(Corpus['text'])\r\n","X_Tfidf = Tfidf_vect.transform(X['text'])\r\n","X['text'] = X_Tfidf.toarray()\r\n","\r\n","split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\r\n","for train_index, test_index in split.split(X, y):\r\n","   Train_X, Test_X = X.loc[train_index], X.loc[test_index]\r\n","   Train_Y, Test_Y = y[train_index], y[test_index]\r\n","\r\n","\r\n","model = LogisticRegression(C=1.0).fit(Train_X, Train_Y)\r\n","start = time.perf_counter()\r\n","model.fit(Train_X, Train_Y)\r\n","stop = time.perf_counter()\r\n","\r\n","#Test Accuracy \r\n","y_pred = model.predict(Test_X)\r\n","test_Accuracy = accuracy_score(Test_Y, y_pred)*100\r\n","\r\n","#Test Accuracy \r\n","y_pred = model.predict(Train_X)\r\n","train_Accuracy = accuracy_score(Train_Y, y_pred)*100\r\n","\r\n","crossvalMean = cross_val_score(model, X, y, cv=10).mean()\r\n","\r\n","curTime = stop - start;\r\n","print(f\"Training Time = {curTime:0.8f} Seconds\")\r\n","print(f\"Test Accuracy = {test_Accuracy}\")\r\n","print(f\"Training Accuracy = {train_Accuracy}\")\r\n","print(f\"Cross Validation Mean = {crossvalMean}\")\r\n","\r\n","\r\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Training Time = 0.00442106 Seconds\n","Test Accuracy = 100.0\n","Training Accuracy = 100.0\n","Cross Validation Mean = 1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VVrqUXetEORG","executionInfo":{"status":"ok","timestamp":1607914039637,"user_tz":480,"elapsed":8083,"user":{"displayName":"Kilo Foxtrot","photoUrl":"","userId":"09050612561505422159"}},"outputId":"5a18fea8-b2c9-48cd-d89b-5201a4b6194e"},"source":["import pandas as pd\r\n","import numpy as np\r\n","import time\r\n","from numpy import array\r\n","from numpy import argmax\r\n","from sklearn.preprocessing import LabelEncoder\r\n","from sklearn.preprocessing import OneHotEncoder\r\n","from nltk.tokenize import word_tokenize\r\n","from nltk import pos_tag\r\n","from nltk.corpus import stopwords\r\n","from nltk.stem import WordNetLemmatizer\r\n","from sklearn.preprocessing import LabelEncoder\r\n","from collections import defaultdict\r\n","from nltk.corpus import wordnet as wn\r\n","from sklearn.feature_extraction.text import TfidfVectorizer\r\n","from sklearn.model_selection import GridSearchCV\r\n","from sklearn import model_selection, svm\r\n","from sklearn.metrics import accuracy_score\r\n","from sklearn.model_selection import StratifiedShuffleSplit\r\n","from sklearn.metrics import classification_report\r\n","from sklearn.linear_model import LogisticRegression\r\n","from sklearn.model_selection import cross_val_score\r\n","\r\n","url=\"https://raw.githubusercontent.com/mgcresswell/TCSS555-Project/main/deceptive-opinion_processed.csv\"\r\n","s=requests.get(url).content\r\n","Corpus = pd.read_csv(io.StringIO(s.decode('utf-8'))) \r\n","\r\n","url=\"https://raw.githubusercontent.com/mgcresswell/TCSS555-Project/main/deceptive-opinion.csv\"\r\n","s=requests.get(url).content\r\n","raw = pd.read_csv(io.StringIO(s.decode('utf-8'))) \r\n","\r\n","y = Corpus['deceptive']\r\n","X = Corpus.drop(['id','deceptive','source'], axis=1)\r\n","\r\n","#feature engineering\r\n","punc = ['`','~','!','(',')','_','-','{','[','}','}',':',';','\"',',','.','?','/','\"\"']\r\n","X['char_count'] = raw[\"text\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\r\n","X['total_length'] = raw['text'].apply(len)\r\n","X['punc_count'] = raw['text'].apply(lambda x : len([a for a in x if a in punc]))\r\n","X['word_count'] = raw[\"text\"].apply(lambda x: len(str(x).split(\" \")))\r\n","X['char_count'] = raw[\"text\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\r\n","X['sentence_count'] = raw[\"text\"].apply(lambda x: len(str(x).split(\".\")))\r\n","X['avg_word_length'] = X['char_count'] / X['word_count']\r\n","X['avg_sentence_length'] = X['word_count'] / X['sentence_count']\r\n","X['word_density'] = X['word_count'] / (X['char_count'] + 1)\r\n","X['punc_count'] = raw['text'].apply(lambda x : len([a for a in x if a in punc]))\r\n","X['total_length'] = raw['text'].apply(len)\r\n","X['capitals'] = raw['text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\r\n","X['num_exclamation_marks'] = raw['text'].apply(lambda x: x.count('!'))\r\n","X['num_question_marks'] = raw['text'].apply(lambda x: x.count('?'))\r\n","X['num_punctuation'] = raw['text'].apply(lambda x: sum(x.count(w) for w in '.,;:'))\r\n","X['num_symbols'] = raw['text'].apply(lambda x: sum(x.count(w) for w in '*&$%'))\r\n","X['num_unique_words'] = raw['text'].apply(lambda x: len(set(w for w in x.split())))\r\n","X['words_vs_unique'] = X['num_unique_words'] / X['word_count']\r\n","X[\"word_unique_percent\"] =  X[\"num_unique_words\"]*100/X['word_count']\r\n","\r\n","label_encoder = LabelEncoder()\r\n","y = label_encoder.fit_transform(y)\r\n","hotelEncoded = label_encoder.fit_transform(X['hotel'])\r\n","polarityEncoded = label_encoder.fit_transform(X['polarity'])\r\n","#sourceEncoded = label_encoder.fit_transform(X['source'])\r\n","\r\n","onehot_encoder = OneHotEncoder(sparse=False)\r\n","hotelEncoded = hotelEncoded.reshape(len(hotelEncoded), 1)\r\n","X['hotel'] = onehot_encoder.fit_transform(hotelEncoded)\r\n","polarityEncoded = polarityEncoded.reshape(len(polarityEncoded), 1)\r\n","X['polarity'] = onehot_encoder.fit_transform(polarityEncoded)\r\n","#sourceEncoded = sourceEncoded.reshape(len(sourceEncoded), 1)\r\n","#X['source'] = onehot_encoder.fit_transform(sourceEncoded)\r\n","\r\n","Tfidf_vect = TfidfVectorizer(max_features=3500)\r\n","Tfidf_vect.fit(Corpus['text'])\r\n","X_Tfidf = Tfidf_vect.transform(X['text'])\r\n","X['text'] = X_Tfidf.toarray()\r\n","\r\n","split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\r\n","for train_index, test_index in split.split(X, y):\r\n","   Train_X, Test_X = X.loc[train_index], X.loc[test_index]\r\n","   Train_Y, Test_Y = y[train_index], y[test_index]\r\n","\r\n","\r\n","model = LogisticRegression(C=1.0, max_iter=10000).fit(Train_X, Train_Y)\r\n","start = time.perf_counter()\r\n","model.fit(Train_X, Train_Y)\r\n","stop = time.perf_counter()\r\n","\r\n","#Test Accuracy \r\n","y_pred = model.predict(Test_X)\r\n","test_Accuracy = accuracy_score(Test_Y, y_pred)*100\r\n","\r\n","#Test Accuracy \r\n","y_pred = model.predict(Train_X)\r\n","train_Accuracy = accuracy_score(Train_Y, y_pred)*100\r\n","\r\n","crossvalMean = cross_val_score(model, X, y, cv=10).mean()\r\n","\r\n","curTime = stop - start;\r\n","print(f\"Training Time = {curTime:0.8f} Seconds\")\r\n","print(f\"Test Accuracy = {test_Accuracy}\")\r\n","print(f\"Training Accuracy = {train_Accuracy}\")\r\n","print(f\"Cross Validation Mean = {crossvalMean}\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Training Time = 0.34026416 Seconds\n","Test Accuracy = 70.41666666666667\n","Training Accuracy = 70.08928571428571\n","Cross Validation Mean = 0.69625\n"],"name":"stdout"}]}]}